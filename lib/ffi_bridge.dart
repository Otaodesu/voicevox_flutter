import 'dart:ffi';
import 'dart:io';

import 'package:ffi/ffi.dart';

import 'generated_bindings.dart';

// å‚è€ƒæ–‡çŒ®ğŸ˜˜: https://github.com/VOICEVOX/voicevox_core/blob/00f891c8664ed302a1b0778ed2eddea4551d6287/example/cpp/unix/simple_tts.cpp

// ã‚‚ã¨ã‚‚ã¨ã¯ã“ã‚ŒãŒvoicevox_flutter.dart
// ãƒã‚¤ãƒ³ã‚¿ãªã‚‹ã‚‚ã®ã‚’æ“ç¸¦ã—ã¦æˆ¦ã†ã€‚

/// VoicevoxCoreLibraryã®ãƒ©ãƒƒãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹
class FFIBridge extends VoicevoxCoreLibrary {
  static final FFIBridge instance = FFIBridge._(
    Platform.isAndroid ? DynamicLibrary.open('libvoicevox_core.so') : DynamicLibrary.open('libvoicevox_core.dylib'),
  );
  FFIBridge._(super.dynamicLibrary);

  /// VoicevoxSynthesizerã®ãƒã‚¤ãƒ³ã‚¿
  late Pointer<VoicevoxSynthesizer> _synthesizerPtr;

  /// èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®ãƒã‚¤ãƒ³ã‚¿ã®ãƒªã‚¹ãƒˆ
  final _loadedModelPtrList = <Pointer<VoicevoxVoiceModelFile>>[];

  /// voicevox_flutterã‚’åˆæœŸåŒ–ã™ã‚‹
  ///
  /// [openJTalkDictPath] OpenJtalkã®è¾æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
  ///
  /// [cpuNumThreads] CPUã‚¹ãƒ¬ãƒƒãƒ‰æ•°
  Future<void> initialize({
    required String openJTalkDictPath,
    int? cpuNumThreads,
  }) async {
    final onnxruntimePtrPtr = malloc<Pointer<VoicevoxOnnxruntime>>();
    final openJTalkDictPathPtr = openJTalkDictPath.toNativeUtf8();
    final openJTalkPtrPtr = malloc<Pointer<OpenJtalkRc>>();
    final outputSynthesizerPtrPtr = malloc<Pointer<VoicevoxSynthesizer>>();

    try {
      // onnxruntimeã‚’æº–å‚™ã™ã‚‹
      final ortLoadResult = voicevox_onnxruntime_load_once(
        voicevox_make_default_load_onnxruntime_options(),
        onnxruntimePtrPtr,
      );
      if (VoicevoxResultCode.fromValue(ortLoadResult) != VoicevoxResultCode.VOICEVOX_RESULT_OK) {
        throw Exception('VOICEVOX_CORE ã‚¨ãƒ©ãƒ¼$ortLoadResult: ${errorcodeToText(ortLoadResult)}');
      }

      // OpenJTalkã‚’æº–å‚™ã™ã‚‹
      final ojtLoadResult = voicevox_open_jtalk_rc_new(
        openJTalkDictPathPtr.cast<Char>(),
        openJTalkPtrPtr,
      );
      if (VoicevoxResultCode.fromValue(ojtLoadResult) != VoicevoxResultCode.VOICEVOX_RESULT_OK) {
        throw Exception('VOICEVOX_CORE ã‚¨ãƒ©ãƒ¼$ojtLoadResult: ${errorcodeToText(ojtLoadResult)}');
      }

      // VOICEVOX_COREã‚’èµ·å‹•ã™ã‚‹ï¼ï¼
      final initializeOptions = voicevox_make_default_initialize_options();

      initializeOptions
        ..acceleration_mode = VoicevoxAccelerationMode.VOICEVOX_ACCELERATION_MODE_CPU.value
        ..cpu_num_threads = cpuNumThreads ?? 0;

      final voicevoxInitResult = voicevox_synthesizer_new(
        onnxruntimePtrPtr.value,
        openJTalkPtrPtr.value,
        initializeOptions,
        outputSynthesizerPtrPtr,
      );
      if (VoicevoxResultCode.fromValue(voicevoxInitResult) != VoicevoxResultCode.VOICEVOX_RESULT_OK) {
        throw Exception('VOICEVOX CORE ã‚¨ãƒ©ãƒ¼$voicevoxInitResult: ${errorcodeToText(voicevoxInitResult)}');
      }

      _synthesizerPtr = outputSynthesizerPtrPtr.value;
    } catch (_) {
      rethrow;
    } finally {
      calloc.free(openJTalkDictPathPtr);
      malloc
        ..free(onnxruntimePtrPtr)
        ..free(openJTalkPtrPtr)
        ..free(outputSynthesizerPtrPtr);
    }
  }

  /// ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€
  ///
  /// [modelPath] vvmãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
  Future<void> loadVoiceModel({required String modelPath}) async {
    final modelPtrPtr = malloc<Pointer<VoicevoxVoiceModelFile>>();
    final modelPathPtr = modelPath.toNativeUtf8();
    try {
      // ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’openã—ã¦ã„ã
      final modelOpenResult = voicevox_voice_model_file_open(
        modelPathPtr.cast<Char>(),
        modelPtrPtr,
      );
      if (VoicevoxResultCode.fromValue(modelOpenResult) != VoicevoxResultCode.VOICEVOX_RESULT_OK) {
        throw Exception('VOICEVOX_CORE ã‚¨ãƒ©ãƒ¼$modelOpenResult: ${errorcodeToText(modelOpenResult)}');
      }

      // ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’loadã—ã¦ã„ãâ€¦ openã§æ‰‹æœ­ã«å–ã£ã¦ã€loadã§å ´ã«å‡ºã™çš„ãªï¼Ÿã‚«ãƒ¼ãƒ‰ã‚²ãƒ¼ãƒ çš„æ€æƒ³ã‚„ãª
      final modelLoadResult = voicevox_synthesizer_load_voice_model(
        _synthesizerPtr,
        modelPtrPtr.value,
      );

      if (VoicevoxResultCode.fromValue(modelLoadResult) != VoicevoxResultCode.VOICEVOX_RESULT_OK) {
        throw Exception('VOICEVOX_CORE ã‚¨ãƒ©ãƒ¼$modelLoadResult: ${errorcodeToText(modelLoadResult)}');
      }
      _loadedModelPtrList.add(modelPtrPtr.value);
    } finally {
      calloc.free(modelPathPtr);
      malloc.free(modelPtrPtr);
    }
  }

  /// ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ AudioQuery ã‚’ç”Ÿæˆã™ã‚‹
  ///
  /// [text] ãƒ†ã‚­ã‚¹ãƒˆ
  ///
  /// [styleId] ã‚¹ã‚¿ã‚¤ãƒ«ID
  String textToAudioQuery(
    String text, {
    required int styleId,
  }) {
    final textPtr = text.toNativeUtf8();
    Pointer<Pointer<Char>> outputPtr = malloc<Pointer<Char>>();
    try {
      final resultCode = voicevox_synthesizer_create_audio_query(
        _synthesizerPtr,
        textPtr.cast<Char>(),
        styleId,
        outputPtr,
      );
      if (VoicevoxResultCode.fromValue(resultCode) != VoicevoxResultCode.VOICEVOX_RESULT_OK) {
        throw Exception('VOICEVOX_CORE ã‚¨ãƒ©ãƒ¼$resultCode: ${errorcodeToText(resultCode)}');
      }

      final query = outputPtr.value.cast<Utf8>().toDartString();
      return query;
    } catch (_) {
      rethrow;
    } finally {
      calloc.free(textPtr);
      malloc.free(outputPtr);
    }
  }

  /// AudioQuery ã‹ã‚‰éŸ³å£°åˆæˆã™ã‚‹
  ///
  /// [query] jsonãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸ AudioQuery
  ///
  /// [styleId] ã‚¹ã‚¿ã‚¤ãƒ«ID
  ///
  /// [outputPath] å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
  Future<void> audioQueryToWav(
    String query, {
    required int styleId,
    required String outputPath,
    bool enableInterrogativeUpspeak = true,
  }) async {
    final outputWavLengthPtr = malloc<UintPtr>();
    final outputWavPtr = malloc<Pointer<Uint8>>();
    try {
      final synthesisOptions = voicevox_make_default_synthesis_options();
      synthesisOptions.enable_interrogative_upspeak = enableInterrogativeUpspeak;

      final queryPtr = query.toNativeUtf8();
      final resultCode = voicevox_synthesizer_synthesis(
        _synthesizerPtr,
        queryPtr.cast<Char>(),
        styleId,
        synthesisOptions,
        outputWavLengthPtr, // generated_bindingsã‚’å†ç”Ÿæˆã™ã‚‹ã¨ãªãœã‹Int(å¤§æ–‡å­—)ã«ãªã£ãŸã®ã§EDITã—ãŸğŸ‘Œ
        outputWavPtr,
      );
      if (VoicevoxResultCode.fromValue(resultCode) != VoicevoxResultCode.VOICEVOX_RESULT_OK) {
        throw Exception('VOICEVOX_CORE ã‚¨ãƒ©ãƒ¼$resultCode: ${errorcodeToText(resultCode)}');
      }
      final wavFile = File(outputPath);
      wavFile.writeAsBytesSync(outputWavPtr.value.asTypedList(outputWavLengthPtr.value));
    } catch (_) {
      rethrow;
    } finally {
      malloc
        ..free(outputWavLengthPtr)
        ..free(outputWavPtr);
    }
  }

  void dispose() {
    for (final modelPtr in _loadedModelPtrList) {
      voicevox_voice_model_file_delete(modelPtr);
    }
    voicevox_synthesizer_delete(_synthesizerPtr);
  }
}

/// VoicevoxCoreLibraryã®ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹
String errorcodeToText(int code) {
  switch (code) {
    case 0:
      return 'æˆåŠŸ';
    case 1:
      return 'open_jtalkè¾æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ãªã„';
    case 3:
      return 'ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±å–å¾—ã«å¤±æ•—ã—ãŸ';
    case 4:
      return 'GPUãƒ¢ãƒ¼ãƒ‰ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„';
    case 6:
      return 'ã‚¹ã‚¿ã‚¤ãƒ«IDã«å¯¾ã™ã‚‹ã‚¹ã‚¿ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸ';
    case 7:
      return 'éŸ³å£°ãƒ¢ãƒ‡ãƒ«IDã«å¯¾ã™ã‚‹éŸ³å£°ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸ';
    case 8:
      return 'æ¨è«–ã«å¤±æ•—ã—ãŸ';
    case 11:
      return 'å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã®è§£æã«å¤±æ•—ã—ãŸ';
    case 12:
      return 'ç„¡åŠ¹ãªutf8æ–‡å­—åˆ—ãŒå…¥åŠ›ã•ã‚ŒãŸ';
    case 13:
      return 'AquesTalké¢¨è¨˜æ³•ã®ãƒ†ã‚­ã‚¹ãƒˆã®è§£æã«å¤±æ•—ã—ãŸ';
    case 14:
      return 'ç„¡åŠ¹ãªAudioQuery';
    case 15:
      return 'ç„¡åŠ¹ãªAccentPhrase';
    case 16:
      return 'ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ãã“ã¨ã«å¤±æ•—ã—ãŸ';
    case 17:
      return 'ZIPå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒèª­ã‚ãªã‹ã£ãŸ';
    case 18:
      return 'ã™ã§ã«èª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹éŸ³å£°ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚‚ã†ã¨ã—ãŸ';
    case 20:
      return 'ãƒ¦ãƒ¼ã‚¶ãƒ¼è¾æ›¸ã‚’èª­ã¿è¾¼ã‚ãªã‹ã£ãŸ';
    case 21:
      return 'ãƒ¦ãƒ¼ã‚¶ãƒ¼è¾æ›¸ã‚’æ›¸ãè¾¼ã‚ãªã‹ã£ãŸ';
    case 22:
      return 'ãƒ¦ãƒ¼ã‚¶ãƒ¼è¾æ›¸ã«å˜èªãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸ';
    case 23:
      return 'OpenJTalkã®ãƒ¦ãƒ¼ã‚¶ãƒ¼è¾æ›¸ã®è¨­å®šã«å¤±æ•—ã—ãŸ';
    case 24:
      return 'ãƒ¦ãƒ¼ã‚¶ãƒ¼è¾æ›¸ã®å˜èªã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã«å¤±æ•—ã—ãŸ';
    case 25:
      return 'UUIDã®å¤‰æ›ã«å¤±æ•—ã—ãŸ';
    case 26:
      return 'ã™ã§ã«èª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹ã‚¹ã‚¿ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚‚ã†ã¨ã—ãŸ';
    case 27:
      return 'ç„¡åŠ¹ãªãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ã‚¿';
    case 28:
      return 'ãƒ¢ãƒ‡ãƒ«ã®å½¢å¼ãŒä¸æ­£';
    case 29:
      return 'æ¨è«–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯åˆæœŸåŒ–ãŒã§ããªã‹ã£ãŸ';
    default:
      return 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼';
  }
}
